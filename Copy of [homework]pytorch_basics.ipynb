{"nbformat":4,"nbformat_minor":0,"metadata":{"hide_input":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false},"colab":{"name":"Copy of [homework]pytorch_basics.ipynb","provenance":[{"file_id":"1zArzJjBEc1WppsxuHWGgRq0cFEYomRdE","timestamp":1585766315403}],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"wscvRoo_Y2bp","colab_type":"text"},"source":["<p style=\"align: center;\"><img align=center src=\"https://s8.hostingkartinok.com/uploads/images/2018/08/308b49fcfbc619d629fe4604bceb67ac.jpg\"  width=400></p>\n","\n","<h3 style=\"text-align: center;\"><b>Физтех-Школа Прикладной математики и информатики (ФПМИ) МФТИ</b></h3>"]},{"cell_type":"code","metadata":{"id":"Lg09ve27Y2br","colab_type":"code","colab":{}},"source":["from matplotlib import pyplot as plt\n","import numpy as np\n","from sklearn import datasets\n","from sklearn.model_selection import train_test_split\n","import torch"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Gbpu-GrgY2bv","colab_type":"text"},"source":["### 1. Нахождение сложной производной"]},{"cell_type":"markdown","metadata":{"id":"GZKVcvtTY2bw","colab_type":"text"},"source":["Найдите производную по x от функции \n","$$\\sin\\left(\\tan(x)\\frac{x^2}{y} + \\ln(e^{-x^2 + 3}+x^3y)\\right)\\tan(x^2e^{x^9})$$\n","\n","При этом надо пользоваться встроенным в PyTorch autograd. Численное вычисление производной может не дать нужный результат."]},{"cell_type":"code","metadata":{"id":"ihvUiIDQY2bx","colab_type":"code","colab":{}},"source":["def find_x_derivative(x, y):\n","    # YOUR CODE HERE\n","    \n","    return # YOUR CODE HERE"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"collapsed":true,"id":"mNbn5UzGY2b0","colab_type":"text"},"source":["# 2. Нахождение косинусной близости\n","\n","Вам даны две матрицы A и B. Необходимо посчитать косинусную близость между строчками матрицы A и столбцами матрицы B. Ответ - матрица чисел, где номер строки - номер строки из матрицы А, а номер столбца - номер столбца из В, от которых бралась косинусная близость.\n","\n","Напомним, что косинусная близость двух векторов - косинус угла между ними. В n-мерном пространстве косинус угла между веткорами удобнее всего через скалярное произведение:\n","$$\\cos(angle(x, y)) = \\frac{x \\cdot y}{\\left\\|x\\right\\| \\left\\|y\\right\\|}$$\n","\n","(Наша операция очень похожа на умножение матриц)"]},{"cell_type":"code","metadata":{"id":"9r2uiysQY2b1","colab_type":"code","colab":{}},"source":["def get_cos_sim(A, B):\n","    \"\"\"\n","        A, B - torch float tensors\n","    \"\"\"\n","    for i in range(A.shape[0]):\n","      A[i] /= A.norm(dim=1)[i]\n","    for i in range(B.shape[1]):\n","      B[:, i] /= B.norm(dim=0)[i]\n","    print(A)\n","    print(B)\n","    res = torch.mm(A, B)\n","    return torch.mean(res)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iiCpcL0P49FX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":170},"outputId":"8185810a-5ec7-4f06-e41d-269d8149cc4a","executionInfo":{"status":"ok","timestamp":1585764721104,"user_tz":-360,"elapsed":886,"user":{"displayName":"Даниил Орел","photoUrl":"","userId":"13151742218398287529"}}},"source":["A = [[1, -47, 25, -3], [10, 17, -15, 22], [-3, -7, 26, 36], [12, -27, -42, 0]]\n","\n","B = [[-50, -13, 1, 10, 1242], [21, 48, -13, -14, -20], [20, 15, 11, 43, 11], [11, 103, 147, 27, -8]]\n","A = torch.tensor(A, dtype=float)\n","B = torch.tensor(B, dtype=float)\n","get_cos_sim(A, B)"],"execution_count":69,"outputs":[{"output_type":"stream","text":["tensor([[ 0.0188, -0.8813,  0.4688, -0.0563],\n","        [ 0.3018,  0.5130, -0.4527,  0.6639],\n","        [-0.0666, -0.1554,  0.5771,  0.7990],\n","        [ 0.2337, -0.5258, -0.8179,  0.0000]], dtype=torch.float64)\n","tensor([[-0.8498, -0.1127,  0.0068,  0.1865,  0.9998],\n","        [ 0.3569,  0.4161, -0.0878, -0.2611, -0.0161],\n","        [ 0.3399,  0.1300,  0.0743,  0.8021,  0.0089],\n","        [ 0.1870,  0.8929,  0.9933,  0.5036, -0.0064]], dtype=torch.float64)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["tensor(0.1498, dtype=torch.float64)"]},"metadata":{"tags":[]},"execution_count":69}]},{"cell_type":"markdown","metadata":{"id":"BR_2JtdtY2b4","colab_type":"text"},"source":["# 3. Линейная регрессия\n","\n","Раньше мы самостоятельно считали производные, чтобы находить веса линейной регрессии с помощью градиентного спуска. Теперь нам нужно использовать для этого PyTorch и его autograd. \n","\n","**Важно**: на самом деле .backward не обновляет содержимое матриц с производными (some_tensor.grad), а прибавляет к ним только что посчитаные значения проивзодных. Это значит, что вызвав .backward дважды, вы получите удвоенную производную. Так как мы обновляем веса в цикле и много раз вызываем .backward, то очень быстро мы получим мусор в some_tensor.grad, если не будем его каждый раз обнулять. Таким образом, в конц итериации после использования производных обнулите значения в матрице производных для всех нужных Вам переменных. Делается это вот так \n","> some\\_tensor.grad.data.zero_()"]},{"cell_type":"code","metadata":{"id":"XbuGEdgBY2b5","colab_type":"code","colab":{}},"source":["class LinearRegression:\n","    def get_loss(self, preds, y):\n","        \"\"\"\n","            @param preds: предсказания модели\n","            @param y: истиные значения\n","            @return mse: значение MSE на переданных данных\n","        \"\"\"\n","        # возьмите средний квадрат ошибки по всем выходным переменным\n","        # то есть сумму квадратов ошибки надо поделить на количество_элементов * количество_таргетов\n","\n","        return torch.sum(torch.mean((y - preds)**2))\n","    \n","    def init_weights(self, input_size, output_size):\n","        \"\"\"\n","            Инициализирует параметры модели\n","            W - матрица размерности (input_size, output_size)\n","            инициализируется рандомными числами из\n","            uniform распределения (torch.rand())\n","            b - вектор размерности (1, output_size)\n","            инициализируется нулями\n","        \"\"\"\n","        torch.manual_seed(0) #необходимо для воспроизводимости результатов\n","        self.W = torch.rand(input_size, output_size,  requires_grad=True)\n","        self.b = torch.zeros(1, output_size, requires_grad=True)\n","\n","    def fit(self, X, y, num_epochs=1000, lr=0.001):\n","        \"\"\"\n","            Обучение модели линейной регрессии методом градиентного спуска\n","            @param X: размерности (num_samples, input_shape)\n","            @param y: размерности (num_samples, output_shape)\n","            @param num_epochs: количество итераций градиентного спуска\n","            @param lr: шаг градиентного спуска\n","            @return metrics: вектор значений MSE на каждом шаге градиентного\n","            спуска.\n","        \"\"\"\n","        self.init_weights(X.shape[1], y.shape[1])\n","        \n","        metrics = []\n","        for _ in range(num_epochs):\n","            preds = self.predict(X)\n","            loss = self.get_loss(preds, y)\n","            loss.backward()\n","            # сделайте вычисления градиентов c помощью Pytorch и обновите веса\n","            # осторожнее, оберните вычитание градиента в \n","            with torch.no_grad():\n","              self.W.data -= lr * self.W.grad.data\n","              self.b.data -= lr * self.b.grad.data\n","            # иначе во время прибавления градиента к переменной создастся очень много нод в дереве операций\n","            # и ваши модели в будущем будут падать от нехватки памяти\n","            #YOUR_CODE\n","            #YOUR_CODE\n","            #YOUR_CODE\n","            #YOUR_CODE\n","            metrics.append(self.get_loss(preds, y).data)\n","            self.W.grad.zero_()\n","            self.b.grad.zero_()\n","\n","        return metrics\n","\n","    def predict(self, X):\n","        \"\"\"\n","            Думаю, тут все понятно. Сделайте свои предсказания :)\n","        \"\"\"\n","      \n","        return torch.mm(X, self.W.type('torch.DoubleTensor').requires_grad_(True)) + self.b"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QQ8GJjFKaY6r","colab_type":"text"},"source":["1. Сгенерируйте данные с помощью make_regression с параметрами n_targets=3, n_features=2, noise=10, random_state=42. \n","2. Обучите модель линейной регрессии, оставив в fit параметры num_epochs и lr по умолчанию (обратите внимание, что перед обучением нужно привести данные к типу, использующимся в torch) \n","2. Посчитайте среднее значение метрики MSE по всем итерациям цикла в fit (массив из значений MSE на каждой итерации возвращается из метода fit). Ответом, который необходимо сдать в систему, будет число, округленное до 3х знаков после запятой."]},{"cell_type":"code","metadata":{"id":"zOVkSg_0Y2b8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":105},"outputId":"9f314e30-b1bd-4379-e10c-b7a60e9b75b1","executionInfo":{"status":"ok","timestamp":1585766286523,"user_tz":-360,"elapsed":1154,"user":{"displayName":"Даниил Орел","photoUrl":"","userId":"13151742218398287529"}}},"source":["X, Y = datasets.make_regression(n_targets=3, n_features=2, noise=10, random_state=42)\n","X = torch.from_numpy(X).float()\n","Y = torch.from_numpy(Y).float()\n","X = torch.tensor(X, dtype=float, requires_grad=True) # YOUR CODE HERE\n","Y = torch.tensor(Y, dtype=float, requires_grad=True)# YOUR CODE HERE\n","model = LinearRegression()\n","mse = model.fit(X, Y)"],"execution_count":97,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  after removing the cwd from sys.path.\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \"\"\"\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"oMgiJA_Va6g_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"9f095f80-0b1c-46f5-d77f-c8c286d60bc8","executionInfo":{"status":"ok","timestamp":1585766290840,"user_tz":-360,"elapsed":744,"user":{"displayName":"Даниил Орел","photoUrl":"","userId":"13151742218398287529"}}},"source":["print(np.mean(mse))"],"execution_count":98,"outputs":[{"output_type":"stream","text":["4256.561075789053\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"iJVuCWOxbACZ","colab_type":"text"},"source":["Здесь предлагаем протестировать метод predict удобным вам образом."]},{"cell_type":"code","metadata":{"id":"XF5Rw27ba-mj","colab_type":"code","colab":{}},"source":["#YOUR CODE"],"execution_count":0,"outputs":[]}]}